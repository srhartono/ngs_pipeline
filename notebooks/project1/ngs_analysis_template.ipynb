{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8221e5c",
   "metadata": {},
   "source": [
    "# NGS Pipeline Analysis - Project 1\n",
    "\n",
    "Comprehensive analysis of multi-condition NGS experiments including:\n",
    "- RNA-seq (gene expression)\n",
    "- EU-seq (nascent RNA)\n",
    "- sDRIP-seq (RNA-DNA hybrids) \n",
    "- ENDseq (5' end mapping)\n",
    "\n",
    "This notebook provides interactive analysis capabilities for the NGS pipeline with flexible treatment/control comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef60e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add the project root to Python path\n",
    "project_root = Path.cwd().parent.parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Import NGS pipeline modules\n",
    "from ngs_pipeline import utils, qc, peaks, quantify, viz, report\n",
    "from ngs_pipeline.utils import setup_logging\n",
    "\n",
    "# Setup\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "setup_logging()\n",
    "\n",
    "print(\"‚úÖ Libraries loaded successfully!\")\n",
    "print(f\"üìÅ Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8081c557",
   "metadata": {},
   "source": [
    "## Configuration and Project Setup\n",
    "\n",
    "Load project configuration and set up paths for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cab6bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load project configuration\n",
    "config_file = project_root / \"config\" / \"project_config.yml\"\n",
    "with open(config_file, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Project information\n",
    "PROJECT_NAME = config['project']['name']\n",
    "DATA_DIR = Path(config['paths']['data_dir'])\n",
    "RESULTS_DIR = Path(config['paths']['results_dir'])\n",
    "NOTEBOOKS_DIR = Path(config['paths']['notebooks_dir'])\n",
    "\n",
    "# Sample information\n",
    "TREATMENTS = config['samples']['treatments']\n",
    "CONTROLS = config['samples']['controls']\n",
    "BATCHES = config['samples']['batches']\n",
    "REPLICATES = config['samples']['replicates']\n",
    "ASSAYS = config['assays']\n",
    "\n",
    "print(f\"üß¨ Project: {PROJECT_NAME}\")\n",
    "print(f\"üìä Treatments: {TREATMENTS}\")\n",
    "print(f\"üî¨ Controls: {CONTROLS}\")\n",
    "print(f\"üß™ Assays: {ASSAYS}\")\n",
    "print(f\"üìã Batches: {BATCHES}\")\n",
    "print(f\"üî¢ Replicates: {REPLICATES}\")\n",
    "\n",
    "# Display directory structure\n",
    "print(f\"\\nüìÅ Directory Structure:\")\n",
    "print(f\"   Data: {DATA_DIR}\")\n",
    "print(f\"   Results: {RESULTS_DIR}\")\n",
    "print(f\"   Notebooks: {NOTEBOOKS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beaef4d",
   "metadata": {},
   "source": [
    "## Sample Metadata Overview\n",
    "\n",
    "Generate and explore the sample metadata for the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58406e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all sample combinations\n",
    "samples_data = []\n",
    "for condition in TREATMENTS + CONTROLS:\n",
    "    for batch in BATCHES:\n",
    "        for rep in REPLICATES:\n",
    "            for assay in ASSAYS:\n",
    "                sample_id = f\"{condition}_{batch}_rep{rep}_{assay}\"\n",
    "                samples_data.append({\n",
    "                    'sample_id': sample_id,\n",
    "                    'condition': condition,\n",
    "                    'batch': batch,\n",
    "                    'replicate': rep,\n",
    "                    'assay': assay,\n",
    "                    'treatment_type': 'treatment' if condition.startswith('Treat') else 'control',\n",
    "                    'fastq_file': f\"{sample_id}.fastq.gz\"\n",
    "                })\n",
    "\n",
    "samples_df = pd.DataFrame(samples_data)\n",
    "\n",
    "print(f\"üìä Total samples: {len(samples_df)}\")\n",
    "print(f\"üß¨ Conditions: {samples_df['condition'].nunique()}\")\n",
    "print(f\"üß™ Assays: {samples_df['assay'].nunique()}\")\n",
    "print(f\"üìã Batches: {samples_df['batch'].nunique()}\")\n",
    "\n",
    "# Display sample distribution\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=('Samples per Condition', 'Samples per Assay', \n",
    "                   'Samples per Batch', 'Treatment vs Control'),\n",
    "    specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}],\n",
    "           [{\"type\": \"bar\"}, {\"type\": \"pie\"}]]\n",
    ")\n",
    "\n",
    "# Condition distribution\n",
    "condition_counts = samples_df['condition'].value_counts()\n",
    "fig.add_trace(go.Bar(x=condition_counts.index, y=condition_counts.values, \n",
    "                     name='Condition'), row=1, col=1)\n",
    "\n",
    "# Assay distribution\n",
    "assay_counts = samples_df['assay'].value_counts()\n",
    "fig.add_trace(go.Bar(x=assay_counts.index, y=assay_counts.values, \n",
    "                     name='Assay'), row=1, col=2)\n",
    "\n",
    "# Batch distribution\n",
    "batch_counts = samples_df['batch'].value_counts()\n",
    "fig.add_trace(go.Bar(x=batch_counts.index, y=batch_counts.values, \n",
    "                     name='Batch'), row=2, col=1)\n",
    "\n",
    "# Treatment vs Control\n",
    "treatment_counts = samples_df['treatment_type'].value_counts()\n",
    "fig.add_trace(go.Pie(labels=treatment_counts.index, values=treatment_counts.values, \n",
    "                     name='Type'), row=2, col=2)\n",
    "\n",
    "fig.update_layout(height=800, title_text=\"Sample Distribution Overview\", showlegend=False)\n",
    "fig.show()\n",
    "\n",
    "# Display first few samples\n",
    "print(\"\\nüìã Sample Overview:\")\n",
    "display(samples_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5509cc72",
   "metadata": {},
   "source": [
    "## Comparison Design Matrix\n",
    "\n",
    "Visualize the experimental design and planned comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155872ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create design matrix for visualization\n",
    "comparisons = []\n",
    "\n",
    "# Add primary comparisons\n",
    "for comp in config['comparisons']['primary']:\n",
    "    comparisons.append({\n",
    "        'name': comp['name'],\n",
    "        'case': comp['case'],\n",
    "        'control': comp['control'],\n",
    "        'type': 'primary',\n",
    "        'description': comp['description']\n",
    "    })\n",
    "\n",
    "# Add batch-specific comparisons\n",
    "for comp in config['comparisons']['batch_specific']:\n",
    "    comparisons.append({\n",
    "        'name': comp['name'],\n",
    "        'case': comp['case'],\n",
    "        'control': comp['control'],\n",
    "        'type': 'batch_specific',\n",
    "        'description': comp['description']\n",
    "    })\n",
    "\n",
    "comparisons_df = pd.DataFrame(comparisons)\n",
    "\n",
    "print(f\"üî¨ Planned comparisons: {len(comparisons_df)}\")\n",
    "print(\"\\nüìä Comparison Types:\")\n",
    "print(comparisons_df['type'].value_counts())\n",
    "\n",
    "# Visualize comparison matrix\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Create comparison matrix\n",
    "conditions = TREATMENTS + CONTROLS\n",
    "comp_matrix = np.zeros((len(conditions), len(conditions)))\n",
    "comp_labels = np.empty((len(conditions), len(conditions)), dtype=object)\n",
    "\n",
    "for i, cond1 in enumerate(conditions):\n",
    "    for j, cond2 in enumerate(conditions):\n",
    "        if i != j:\n",
    "            # Check if this comparison exists\n",
    "            comp_name = f\"{cond1}_vs_{cond2}\"\n",
    "            if any(comp_name in comp['name'] for comp in comparisons):\n",
    "                comp_matrix[i, j] = 1\n",
    "                comp_labels[i, j] = \"‚úì\"\n",
    "\n",
    "# Plot heatmap\n",
    "sns.heatmap(comp_matrix, \n",
    "            xticklabels=conditions, \n",
    "            yticklabels=conditions,\n",
    "            annot=comp_labels, \n",
    "            fmt='', \n",
    "            cmap='RdYlBu_r',\n",
    "            cbar_kws={'label': 'Comparison Planned'},\n",
    "            ax=ax)\n",
    "\n",
    "ax.set_title('Experimental Design Matrix\\n(Rows = Case, Columns = Control)')\n",
    "ax.set_xlabel('Control Conditions')\n",
    "ax.set_ylabel('Case Conditions')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display comparisons table\n",
    "print(\"\\nüìã Planned Comparisons:\")\n",
    "display(comparisons_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ff297e",
   "metadata": {},
   "source": [
    "## Data Quality Overview\n",
    "\n",
    "Check for data availability and basic quality metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3704173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data availability\n",
    "data_status = []\n",
    "missing_files = []\n",
    "\n",
    "for _, sample in samples_df.iterrows():\n",
    "    fastq_path = DATA_DIR / sample['fastq_file']\n",
    "    \n",
    "    if fastq_path.exists():\n",
    "        # Get file size\n",
    "        file_size = fastq_path.stat().st_size / (1024**2)  # MB\n",
    "        data_status.append({\n",
    "            'sample_id': sample['sample_id'],\n",
    "            'condition': sample['condition'],\n",
    "            'assay': sample['assay'],\n",
    "            'file_exists': True,\n",
    "            'file_size_mb': file_size\n",
    "        })\n",
    "    else:\n",
    "        missing_files.append(sample['fastq_file'])\n",
    "        data_status.append({\n",
    "            'sample_id': sample['sample_id'],\n",
    "            'condition': sample['condition'],\n",
    "            'assay': sample['assay'],\n",
    "            'file_exists': False,\n",
    "            'file_size_mb': 0\n",
    "        })\n",
    "\n",
    "data_status_df = pd.DataFrame(data_status)\n",
    "\n",
    "# Summary statistics\n",
    "total_samples = len(data_status_df)\n",
    "available_samples = data_status_df['file_exists'].sum()\n",
    "missing_count = len(missing_files)\n",
    "\n",
    "print(f\"üìä Data Availability Summary:\")\n",
    "print(f\"   Total samples: {total_samples}\")\n",
    "print(f\"   Available: {available_samples}\")\n",
    "print(f\"   Missing: {missing_count}\")\n",
    "\n",
    "if missing_count > 0:\n",
    "    print(f\"\\n‚ùå Missing files:\")\n",
    "    for file in missing_files[:10]:  # Show first 10\n",
    "        print(f\"   - {file}\")\n",
    "    if len(missing_files) > 10:\n",
    "        print(f\"   ... and {len(missing_files) - 10} more\")\n",
    "\n",
    "# File size distribution by assay\n",
    "if available_samples > 0:\n",
    "    available_data = data_status_df[data_status_df['file_exists'] == True]\n",
    "    \n",
    "    fig = px.box(available_data, \n",
    "                 x='assay', \n",
    "                 y='file_size_mb',\n",
    "                 color='condition',\n",
    "                 title='File Size Distribution by Assay and Condition')\n",
    "    fig.update_layout(height=500)\n",
    "    fig.show()\n",
    "    \n",
    "    print(f\"\\nüìà File Size Statistics (MB):\")\n",
    "    size_stats = available_data.groupby('assay')['file_size_mb'].describe()\n",
    "    display(size_stats.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c513aef5",
   "metadata": {},
   "source": [
    "## Generate Test Data\n",
    "\n",
    "If data files are missing, generate synthetic test data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898ae15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test data if needed\n",
    "if missing_count > 0:\n",
    "    print(\"üîß Generating synthetic test data...\")\n",
    "    \n",
    "    # Create data directory if it doesn't exist\n",
    "    DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Import test data generator\n",
    "    from test.generate_test_data import create_sample_data, create_samplesheet\n",
    "    \n",
    "    # Generate test data with reduced read count for speed\n",
    "    create_sample_data(DATA_DIR, num_reads=1000)\n",
    "    \n",
    "    # Create sample sheet\n",
    "    create_samplesheet(DATA_DIR)\n",
    "    \n",
    "    print(\"‚úÖ Test data generated successfully!\")\n",
    "    \n",
    "    # Refresh data status\n",
    "    data_status = []\n",
    "    for _, sample in samples_df.iterrows():\n",
    "        fastq_path = DATA_DIR / sample['fastq_file']\n",
    "        if fastq_path.exists():\n",
    "            file_size = fastq_path.stat().st_size / (1024**2)\n",
    "            data_status.append({\n",
    "                'sample_id': sample['sample_id'],\n",
    "                'condition': sample['condition'],\n",
    "                'assay': sample['assay'],\n",
    "                'file_exists': True,\n",
    "                'file_size_mb': file_size\n",
    "            })\n",
    "    \n",
    "    data_status_df = pd.DataFrame(data_status)\n",
    "    print(f\"üìä Updated availability: {len(data_status_df)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b068b92",
   "metadata": {},
   "source": [
    "## RNA-seq Expression Analysis\n",
    "\n",
    "Analyze RNA-seq data for differential expression across conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbdacae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter RNA-seq samples\n",
    "rnaseq_samples = samples_df[samples_df['assay'] == 'rnaseq'].copy()\n",
    "print(f\"üß¨ RNA-seq samples: {len(rnaseq_samples)}\")\n",
    "\n",
    "# Create mock expression data for demonstration\n",
    "# In a real analysis, this would come from quantification results\n",
    "np.random.seed(42)\n",
    "genes = [f\"GENE_{i:04d}\" for i in range(1000)]\n",
    "n_samples = len(rnaseq_samples)\n",
    "\n",
    "# Generate mock count data with treatment effects\n",
    "expression_data = {}\n",
    "for _, sample in rnaseq_samples.iterrows():\n",
    "    # Base expression + treatment effect + batch effect + noise\n",
    "    base_expr = np.random.negative_binomial(20, 0.3, len(genes))\n",
    "    \n",
    "    # Add treatment effect for some genes\n",
    "    if sample['treatment_type'] == 'treatment':\n",
    "        # Upregulate some genes, downregulate others\n",
    "        upregulated = np.random.choice(len(genes), 50, replace=False)\n",
    "        downregulated = np.random.choice(len(genes), 30, replace=False)\n",
    "        base_expr[upregulated] *= np.random.uniform(2, 5, len(upregulated))\n",
    "        base_expr[downregulated] *= np.random.uniform(0.2, 0.8, len(downregulated))\n",
    "    \n",
    "    # Add batch effect\n",
    "    if sample['batch'] == 'batch2':\n",
    "        base_expr *= np.random.uniform(0.8, 1.2, len(genes))\n",
    "    \n",
    "    expression_data[sample['sample_id']] = base_expr\n",
    "\n",
    "# Create expression matrix\n",
    "expr_df = pd.DataFrame(expression_data, index=genes)\n",
    "print(f\"üìä Expression matrix: {expr_df.shape[0]} genes √ó {expr_df.shape[1]} samples\")\n",
    "\n",
    "# Normalize (log2 + 1 transformation)\n",
    "expr_log = np.log2(expr_df + 1)\n",
    "\n",
    "# PCA analysis\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "expr_scaled = scaler.fit_transform(expr_log.T)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=3)\n",
    "pca_result = pca.fit_transform(expr_scaled)\n",
    "\n",
    "# Add PCA results to sample info\n",
    "rnaseq_samples['PC1'] = pca_result[:, 0]\n",
    "rnaseq_samples['PC2'] = pca_result[:, 1]\n",
    "rnaseq_samples['PC3'] = pca_result[:, 2]\n",
    "\n",
    "# Plot PCA\n",
    "fig = px.scatter(rnaseq_samples, \n",
    "                 x='PC1', y='PC2',\n",
    "                 color='condition',\n",
    "                 symbol='batch',\n",
    "                 title=f'PCA of RNA-seq Samples<br>PC1: {pca.explained_variance_ratio_[0]:.1%}, PC2: {pca.explained_variance_ratio_[1]:.1%}',\n",
    "                 hover_data=['sample_id'])\n",
    "fig.update_layout(height=500)\n",
    "fig.show()\n",
    "\n",
    "print(f\"üìà PCA Explained Variance:\")\n",
    "for i, var in enumerate(pca.explained_variance_ratio_[:3]):\n",
    "    print(f\"   PC{i+1}: {var:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7146d0",
   "metadata": {},
   "source": [
    "## Differential Expression Analysis\n",
    "\n",
    "Perform differential expression analysis for key comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fd74c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock differential expression results\n",
    "# In practice, this would use DESeq2 or similar tools\n",
    "\n",
    "def mock_differential_expression(case_condition, control_condition, expr_df, sample_info):\n",
    "    \"\"\"Generate mock differential expression results.\"\"\"\n",
    "    \n",
    "    # Get samples for comparison\n",
    "    case_samples = sample_info[sample_info['condition'] == case_condition]['sample_id'].tolist()\n",
    "    control_samples = sample_info[sample_info['condition'] == control_condition]['sample_id'].tolist()\n",
    "    \n",
    "    if not case_samples or not control_samples:\n",
    "        print(f\"‚ö†Ô∏è No samples found for {case_condition} vs {control_condition}\")\n",
    "        return None\n",
    "    \n",
    "    # Calculate mean expression\n",
    "    case_mean = expr_df[case_samples].mean(axis=1)\n",
    "    control_mean = expr_df[control_samples].mean(axis=1)\n",
    "    \n",
    "    # Calculate fold change\n",
    "    log2fc = case_mean - control_mean\n",
    "    \n",
    "    # Mock p-values (random but consistent)\n",
    "    np.random.seed(hash(case_condition + control_condition) % 2**32)\n",
    "    pvalues = np.random.beta(0.5, 10, len(expr_df))  # Most genes not significant\n",
    "    \n",
    "    # Adjust some p-values for genes with large fold changes\n",
    "    large_fc_genes = np.abs(log2fc) > 1\n",
    "    pvalues[large_fc_genes] *= 0.1  # Make them more significant\n",
    "    \n",
    "    # FDR correction (simplified)\n",
    "    from scipy import stats\n",
    "    _, padj = stats.false_discovery_control(pvalues, method='benjamini-hochberg')\n",
    "    \n",
    "    # Create results dataframe\n",
    "    results = pd.DataFrame({\n",
    "        'gene_id': expr_df.index,\n",
    "        'case_mean': case_mean,\n",
    "        'control_mean': control_mean,\n",
    "        'log2FoldChange': log2fc,\n",
    "        'pvalue': pvalues,\n",
    "        'padj': padj\n",
    "    })\n",
    "    \n",
    "    # Add significance flags\n",
    "    results['significant'] = (results['padj'] < 0.05) & (np.abs(results['log2FoldChange']) > 1)\n",
    "    results['direction'] = np.where(results['log2FoldChange'] > 0, 'Up', 'Down')\n",
    "    \n",
    "    return results.sort_values('pvalue')\n",
    "\n",
    "# Run differential expression for primary comparisons\n",
    "de_results = {}\n",
    "for comp in config['comparisons']['primary']:\n",
    "    case = comp['case']\n",
    "    control = comp['control']\n",
    "    comp_name = comp['name']\n",
    "    \n",
    "    print(f\"üî¨ Running DE analysis: {comp_name}\")\n",
    "    results = mock_differential_expression(case, control, expr_log, rnaseq_samples)\n",
    "    \n",
    "    if results is not None:\n",
    "        de_results[comp_name] = results\n",
    "        \n",
    "        n_total = len(results)\n",
    "        n_sig = results['significant'].sum()\n",
    "        n_up = ((results['significant']) & (results['log2FoldChange'] > 0)).sum()\n",
    "        n_down = ((results['significant']) & (results['log2FoldChange'] < 0)).sum()\n",
    "        \n",
    "        print(f\"   Total genes: {n_total}\")\n",
    "        print(f\"   Significant: {n_sig} ({n_sig/n_total:.1%})\")\n",
    "        print(f\"   Upregulated: {n_up}\")\n",
    "        print(f\"   Downregulated: {n_down}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Completed {len(de_results)} differential expression analyses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4935a0",
   "metadata": {},
   "source": [
    "## Visualization Dashboard\n",
    "\n",
    "Create interactive plots for exploring differential expression results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ce1a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multi-panel visualization dashboard\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def create_de_dashboard(de_results):\n",
    "    \"\"\"Create interactive dashboard for DE results.\"\"\"\n",
    "    \n",
    "    n_comparisons = len(de_results)\n",
    "    if n_comparisons == 0:\n",
    "        print(\"No DE results to display\")\n",
    "        return\n",
    "    \n",
    "    # Create subplots\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=('DE Summary', 'Volcano Plot', 'MA Plot', 'Top Genes'),\n",
    "        specs=[[{\"type\": \"bar\"}, {\"type\": \"scatter\"}],\n",
    "               [{\"type\": \"scatter\"}, {\"type\": \"bar\"}]]\n",
    "    )\n",
    "    \n",
    "    # Summary statistics\n",
    "    summary_data = []\n",
    "    for comp_name, results in de_results.items():\n",
    "        n_up = ((results['significant']) & (results['log2FoldChange'] > 0)).sum()\n",
    "        n_down = ((results['significant']) & (results['log2FoldChange'] < 0)).sum()\n",
    "        summary_data.extend([\n",
    "            {'comparison': comp_name, 'direction': 'Up', 'count': n_up},\n",
    "            {'comparison': comp_name, 'direction': 'Down', 'count': n_down}\n",
    "        ])\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    \n",
    "    # Plot summary\n",
    "    for direction in ['Up', 'Down']:\n",
    "        data = summary_df[summary_df['direction'] == direction]\n",
    "        fig.add_trace(go.Bar(\n",
    "            x=data['comparison'], \n",
    "            y=data['count'],\n",
    "            name=f'{direction}regulated',\n",
    "            marker_color='red' if direction == 'Up' else 'blue'\n",
    "        ), row=1, col=1)\n",
    "    \n",
    "    # Volcano plot (first comparison)\n",
    "    if de_results:\n",
    "        first_comp = list(de_results.keys())[0]\n",
    "        first_results = de_results[first_comp]\n",
    "        \n",
    "        # Volcano plot\n",
    "        colors = ['red' if sig and lfc > 0 else 'blue' if sig and lfc < 0 else 'gray' \n",
    "                 for sig, lfc in zip(first_results['significant'], first_results['log2FoldChange'])]\n",
    "        \n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=first_results['log2FoldChange'],\n",
    "            y=-np.log10(first_results['pvalue']),\n",
    "            mode='markers',\n",
    "            marker=dict(color=colors, size=4, opacity=0.6),\n",
    "            text=first_results['gene_id'],\n",
    "            name='Genes',\n",
    "            showlegend=False\n",
    "        ), row=1, col=2)\n",
    "        \n",
    "        # MA plot\n",
    "        avg_expr = (first_results['case_mean'] + first_results['control_mean']) / 2\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=avg_expr,\n",
    "            y=first_results['log2FoldChange'],\n",
    "            mode='markers',\n",
    "            marker=dict(color=colors, size=4, opacity=0.6),\n",
    "            text=first_results['gene_id'],\n",
    "            name='Genes',\n",
    "            showlegend=False\n",
    "        ), row=2, col=1)\n",
    "        \n",
    "        # Top genes\n",
    "        top_genes = first_results.nsmallest(20, 'padj')\n",
    "        fig.add_trace(go.Bar(\n",
    "            x=-np.log10(top_genes['padj']),\n",
    "            y=top_genes['gene_id'],\n",
    "            orientation='h',\n",
    "            name='Top Genes',\n",
    "            showlegend=False\n",
    "        ), row=2, col=2)\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        title_text=f\"Differential Expression Dashboard - {PROJECT_NAME}\",\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    # Update axis labels\n",
    "    fig.update_xaxes(title_text=\"Comparison\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Number of Genes\", row=1, col=1)\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"log2 Fold Change\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"-log10(p-value)\", row=1, col=2)\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"Average Expression\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"log2 Fold Change\", row=2, col=1)\n",
    "    \n",
    "    fig.update_xaxes(title_text=\"-log10(adj p-value)\", row=2, col=2)\n",
    "    fig.update_yaxes(title_text=\"Gene\", row=2, col=2)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create and display dashboard\n",
    "dashboard = create_de_dashboard(de_results)\n",
    "if dashboard:\n",
    "    dashboard.show()\n",
    "\n",
    "# Display results summary\n",
    "if de_results:\n",
    "    print(\"\\nüìä Differential Expression Summary:\")\n",
    "    for comp_name, results in de_results.items():\n",
    "        sig_genes = results[results['significant']]\n",
    "        print(f\"\\nüî¨ {comp_name}:\")\n",
    "        print(f\"   Significant genes: {len(sig_genes)}\")\n",
    "        if len(sig_genes) > 0:\n",
    "            print(f\"   Top upregulated: {sig_genes[sig_genes['log2FoldChange'] > 0].iloc[0]['gene_id'] if len(sig_genes[sig_genes['log2FoldChange'] > 0]) > 0 else 'None'}\")\n",
    "            print(f\"   Top downregulated: {sig_genes[sig_genes['log2FoldChange'] < 0].iloc[0]['gene_id'] if len(sig_genes[sig_genes['log2FoldChange'] < 0]) > 0 else 'None'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2316282",
   "metadata": {},
   "source": [
    "## Export Results\n",
    "\n",
    "Save analysis results and generate reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67061f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results directory\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save differential expression results\n",
    "de_output_dir = RESULTS_DIR / \"differential_expression\"\n",
    "de_output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for comp_name, results in de_results.items():\n",
    "    output_file = de_output_dir / f\"{comp_name}_results.tsv\"\n",
    "    results.to_csv(output_file, sep='\\t', index=False)\n",
    "    print(f\"üíæ Saved: {output_file}\")\n",
    "\n",
    "# Save sample metadata\n",
    "samples_output = RESULTS_DIR / \"sample_metadata.tsv\"\n",
    "samples_df.to_csv(samples_output, sep='\\t', index=False)\n",
    "print(f\"üíæ Saved: {samples_output}\")\n",
    "\n",
    "# Save expression matrix\n",
    "expr_output = RESULTS_DIR / \"expression_matrix.tsv\"\n",
    "expr_df.to_csv(expr_output, sep='\\t')\n",
    "print(f\"üíæ Saved: {expr_output}\")\n",
    "\n",
    "# Generate summary report\n",
    "summary_report = {\n",
    "    'project': PROJECT_NAME,\n",
    "    'date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'total_samples': len(samples_df),\n",
    "    'conditions': samples_df['condition'].unique().tolist(),\n",
    "    'assays': ASSAYS,\n",
    "    'comparisons_analyzed': list(de_results.keys()),\n",
    "    'total_genes': len(expr_df) if len(expr_df) > 0 else 0,\n",
    "    'significant_genes_per_comparison': {\n",
    "        comp: int(results['significant'].sum()) \n",
    "        for comp, results in de_results.items()\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save summary\n",
    "summary_output = RESULTS_DIR / \"analysis_summary.json\"\n",
    "import json\n",
    "with open(summary_output, 'w') as f:\n",
    "    json.dump(summary_report, f, indent=2)\n",
    "\n",
    "print(f\"üíæ Saved: {summary_output}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Analysis complete!\")\n",
    "print(f\"üìÅ Results saved to: {RESULTS_DIR}\")\n",
    "print(f\"üî¨ Analyzed {len(de_results)} comparisons\")\n",
    "print(f\"üß¨ Processed {len(samples_df)} samples across {len(ASSAYS)} assays\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9e7394",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "This notebook provides a foundation for NGS analysis with the new pipeline structure. Key features:\n",
    "\n",
    "### ‚úÖ Completed in this Analysis:\n",
    "- Project-based organization with flexible folder structure\n",
    "- Multi-condition experimental design (Treat1/Treat2 vs Control1/Control2)\n",
    "- Batch and replicate handling\n",
    "- Interactive visualization dashboard\n",
    "- Configurable comparison system\n",
    "\n",
    "### üîÑ For Production Analysis:\n",
    "1. **Real Data Processing**: Replace mock data with actual sequencing results\n",
    "2. **Snakemake Workflow**: Use `workflow/Snakefile` for automated processing\n",
    "3. **Quality Control**: Run comprehensive QC with FastQC/MultiQC\n",
    "4. **Peak Analysis**: Analyze sDRIP-seq and ENDseq peaks\n",
    "5. **Integration**: Combine results across assay types\n",
    "\n",
    "### üõ†Ô∏è Pipeline Commands:\n",
    "```bash\n",
    "# Run Snakemake workflow\n",
    "snakemake -s workflow/Snakefile --configfile config/project_config.yml --cores 8\n",
    "\n",
    "# Run individual analysis modules\n",
    "ngs_pipeline qc --input data/project1/ --output results/project1/qc/\n",
    "ngs_pipeline quantify --input results/project1/mapping/ --output results/project1/expression/\n",
    "```\n",
    "\n",
    "### üìä Configuration:\n",
    "- Modify `config/project_config.yml` for different comparisons\n",
    "- Add new conditions, batches, or assays as needed\n",
    "- Customize analysis parameters\n",
    "\n",
    "The pipeline now supports flexible experimental designs with batch effects, multiple treatments/controls, and comprehensive visualization capabilities."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
